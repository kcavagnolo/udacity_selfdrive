{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import functools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        self.inbound_layers = inbound_layers\n",
    "        self.value = None\n",
    "        self.outbound_layers = []\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward():\n",
    "        raise NotImplemenetedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    While it may be strange to consider an input a layer when\n",
    "    an input is only an individual node in a layer, for the sake\n",
    "    of simpler code we'll still use Layer as the base class.\n",
    "    \n",
    "    Think of Input as collating many individual input nodes into\n",
    "    a Layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # An Input layer has no inbound layers,\n",
    "        # so no need to pass anything to the Layer instantiator\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "    \n",
    "    def backward(self):\n",
    "        # An Input Layer has no inputs so we refer to ourself\n",
    "        # for the gradient\n",
    "        self.gradients = {self: 0}\n",
    "        for n in self.outbound_Layers:\n",
    "            self.gradients[self] += n.gradients[self]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, inbound_layer, weights, bias):\n",
    "        # Notice the ordering of the input layers passed to the\n",
    "        # Layer constructor.\n",
    "        Layer.__init__(self, [inbound_layer, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        X = self.inbound_layers[0].value\n",
    "        W = self.inbound_layers[1].value\n",
    "        b = self.inbound_layers[2].value\n",
    "        self.value = np.dot(X, W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def __init__(self, layer):\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "\n",
    "        Return the result of the sigmoid function.\n",
    "        \"\"\"\n",
    "        return 1./(1.+np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = self._sigmoid(self.inbound_layers[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSE(Layer):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last layer for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Layer.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_layers[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_layers[1].value.reshape(-1, 1)\n",
    "        # TODO: your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(output_layer, sorted_layers):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_layer`: A Layer in the graph, should be the output layer (have no outgoing edges).\n",
    "        `sorted_layers`: a topologically sorted list of layers.\n",
    "\n",
    "    Returns the output layer's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_layers:\n",
    "        n.forward()\n",
    "\n",
    "    return output_layer.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.  4.]\n",
      " [-9.  4.]]\n"
     ]
    }
   ],
   "source": [
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "\n",
    "x = np.array([[-1., -2.], [-1, -2]])\n",
    "w = np.array([[2., -3], [2., -3]])\n",
    "b = np.array([-3., -5])\n",
    "\n",
    "feed_dict = {inputs: x, weights: w, bias: b}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[-9., 4.],\n",
    "[-9., 4.]]\n",
    "\"\"\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.23394576e-04   9.82013790e-01]\n",
      " [  1.23394576e-04   9.82013790e-01]]\n"
     ]
    }
   ],
   "source": [
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "g = Sigmoid(f)\n",
    "\n",
    "x = np.array([[-1., -2.], [-1, -2]])\n",
    "w = np.array([[2., -3], [2., -3]])\n",
    "b = np.array([-3., -5])\n",
    "\n",
    "feed_dict = {inputs: x, weights: w, bias: b}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(g, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[  1.23394576e-04   9.82013790e-01]\n",
    " [  1.23394576e-04   9.82013790e-01]]\n",
    "\"\"\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
